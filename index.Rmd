---
title: "Predicting EPL Full-Time Result using Random Forest"
author: "Your Name"
date: "08-Oct-2024"
output: github_document
---

# Introduction

This tutorial demonstrates machine learning classification using numerical data in the context of the English Premier League (EPL). We predict the full-time result (Home win, Draw, Away win) based on betting odds and compare their predictive power. The focus is on showing how to implement a classification model, not on achieving high accuracy. Team effects, time effects, and other contextual factors are not considered.

## Step 1: Load and Install Required Libraries

In this first step, we ensure that the necessary libraries are installed. I recommend running this code as it will install any missing packages before proceeding with the tutorial.

```{r install-libraries, eval=TRUE, message=FALSE, warning=FALSE, include=TRUE}
# Install necessary libraries if they aren't already installed
if (!require(dplyr)) install.packages("dplyr")
if (!require(caret)) install.packages("caret")
if (!require(randomForest)) install.packages("randomForest")
if (!require(e1071)) install.packages("e1071")  # e1071 is required by caret

# Load the libraries 
library(dplyr)
library(caret)
library(randomForest)
```

## Step 2: Prepare the Data

Now, we load the dataset and select the relevant variables (betting odds and final game result) listed as follows:

- **FTHG**: *Full Time Home Team Goals*  
- **FTAG**: *Full Time Away Team Goals*  
- **FTR**: *Full Time Result (H=Home Win, NH=Not a Home Win)*  
- **B365H**: *Bet365 home win odds*  
- **B365D**: *Bet365 draw odds*  
- **B365A**: *Bet365 away win odds*  
- **IWH**: *Interwetten home win odds*  
- **IWD**: *Interwetten draw odds*  
- **IWA**: *Interwetten away win odds*  
- **LBH**: *Ladbrokes home win odds*  
- **LBD**: *Ladbrokes draw odds*  
- **LBA**: *Ladbrokes away win odds*  
- **WHH**: *William Hill home win odds*  
- **WHD**: *William Hill draw odds*  
- **WHA**: *William Hill away win odds*

Note that the **FTR** variable originally has two levels (*Home Win* or *Not Home Win*). We recode it into three levels: *Home Win*, *Draw*, and *Away Win*, to align with the odds data from the four companies: Bet365, Ladbrokes, William Hill, and Interwetten, each offering odds for these three outcomes.


```{r load-data, include=TRUE}
# Load EPL results and betting odds data from a CSV file (available on the github repository of this page)
epl_data <- read.csv("final_dataset_with_odds.csv") %>%
  select(FTHG, FTAG, FTR, B365H, B365D, B365A, IWH, IWD, IWA, LBH, LBD, LBA, WHH, WHD, WHA)

# Recode the Full-Time Result (FTR) based on Full-Time Home Goals (FTHG) and Full-Time Away Goals (FTAG)
epl_data <- epl_data %>%
  mutate(FTR = case_when(
    FTHG > FTAG ~ "H",  # Home win
    FTHG == FTAG ~ "D", # Draw
    FTHG < FTAG ~ "A")  # Away Win
    ) %>%
  select(-FTHG, -FTAG)

# Convert FTR to a factor variable
epl_data$FTR <- as.factor(epl_data$FTR)

# check data for any inconsistencies or missing values
summary(epl_data)

```

## Step 3: Split Data into Training and Testing Sets

In this step, we split the dataset into two parts. We use 80% of the data to train our model and 20% to test its performance. This is a common approach in machine learning to avoid over-fitting and test model efficiency.


```{r split train/test, include=TRUE}
# Set seed for reproducibility
set.seed(1234)

# Split the data into 80% training and 20% testing
train_row_numbers <- createDataPartition(epl_data$FTR, p = 0.8, list = FALSE)
train_data <- epl_data[train_row_numbers, ]
test_data <- epl_data[-train_row_numbers, ]

```

## Step 4: Train a Model using an algorithm (we use Random Forest)

While many algorithms are available, we will use Random Forest for its simplicity and ability to highlight variable importance. This will allow us to compare which betting odds have the strongest explanatory power.

```{r model, include=TRUE}
# Set seed for reproducibility
set.seed(100)

# Train the model using Random Forest
model_rf <- train(FTR ~ ., data = train_data, method = 'rf')

# display model
model_rf

```

Which betting companies' odds have the best explaining power?

```{r Variable imp, include=TRUE}
# Display the variable importance (which betting companies' odds have the best explaining power?)
varimp_rf <- varImp(model_rf)
plot(varimp_rf, main = "Horserace of Betting Odds")

```


## Step 5: Make Predictions and Evaluate the Model

Now, we test the model on the test dataset and predict the Full-Time Result (FTR). To evaluate the model's performance, we use a confusion matrix, which provides insight into how accurately the model classifies each outcome.

```{r predict, include=TRUE}
# Make predictions on the test set
predicted <- predict(model_rf, test_data)

# Generate a confusion matrix to validate the results
confusion_matrix <- confusionMatrix(reference = test_data$FTR, data = predicted, mode = 'everything')
confusion_matrix


```

## Step 5: Conclusion

This tutorial provide a simple context to implement machine learning classification using numerical predictors. The focus of this tutorial is not  on accuracy but rather on providing a basic example with code for learning and experimentation. The model can be further optimized by incorporating additional factors (such as team performance, year effects, etc.) and can be adopted to one's own research contexts/settings.


